{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import glob\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    " \n",
    "# import the necessary packages\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Conv2D, BatchNormalization\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Activation, Flatten, Dropout, Lambda\n",
    "from keras.layers.advanced_activations import ELU\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import ModelCheckpoint, Callback\n",
    "from keras.layers.core import Dense\n",
    "# from keras.optimizers import SGD\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "vehicle_image_arr = glob.glob('./data.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data1.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data2.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data3.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data4.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data5.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data6.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data7.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data8.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data9.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data10.MP4/*.jpg')\n",
    "vehicle_image_arr += glob.glob('./data11.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data12.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data13.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data14.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data15.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data16.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data17.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data18.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data19.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data20.MP4/*.jpg')\n",
    "# vehicle_image_arr += glob.glob('./data21.MP4/*.jpg')\n",
    "\n",
    "txt_files = glob.glob('./data.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data1.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data2.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data3.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data4.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data5.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data6.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data7.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data8.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data9.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data10.MP4/*.lines.txt')\n",
    "txt_files += glob.glob('./data11.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data12.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data13.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data14.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data15.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data16.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data17.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data18.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data19.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data20.MP4/*.lines.txt')\n",
    "# txt_files += glob.glob('./data21.MP4/*.lines.txt')\n",
    "\n",
    "normPoints = 96\n",
    "vehicle_images_original=[]\n",
    "txtData = []\n",
    "\n",
    "def normalizePoints(lane):\n",
    "    while (len(lane) < normPoints):\n",
    "        lane.append(lane[len(lane)-2])\n",
    "        lane.append(lane[len(lane)-2])\n",
    "    if (len(lane)>normPoints):\n",
    "        lane = lane[:normPoints]\n",
    "        \n",
    "\n",
    "for imagePath in vehicle_image_arr:\n",
    "    readImage=cv2.imread(imagePath)\n",
    "    vehicle_images_original.append(readImage)\n",
    "    txtFileName = './'+imagePath.split('/')[1]+'/'+ imagePath.split('/')[2].split('.')[0] +'.lines.txt'\n",
    "    with open(txtFileName, 'rt') as fd:\n",
    "        txtData.append(fd.readlines())\n",
    "\n",
    "print('Reading of Vehicle Images Done', len(vehicle_image_arr))\n",
    "\n",
    "\n",
    "imgplot = plt.imshow(vehicle_images_original[250])\n",
    "data1 = txtData[250][0]\n",
    "data2 = txtData[250][1]\n",
    "data3 = txtData[250][2]\n",
    "data4 = txtData[250][3]\n",
    "dataSplit1 = [float(val) for val in data1.split()]\n",
    "dataSplit2 = [float(val) for val in data2.split()]\n",
    "dataSplit3 = [float(val) for val in data3.split()]\n",
    "dataSplit4 = [float(val) for val in data4.split()]\n",
    "outputData = []\n",
    "\n",
    "for i in txtData:\n",
    "    while (len(i)<4):\n",
    "        i.append(' '.join(str(e) for e in [0]*normPoints))\n",
    "    lane1 = [float(val) for val in i[0].split()]\n",
    "    lane2 = [float(val) for val in i[1].split()]\n",
    "    lane3 = [float(val) for val in i[2].split()]\n",
    "    lane4 = [float(val) for val in i[3].split()]\n",
    "    normalizePoints(lane1)\n",
    "    normalizePoints(lane2)\n",
    "    normalizePoints(lane3)\n",
    "    normalizePoints(lane4)\n",
    "    outputData.append(lane1 + lane2 +lane3 + lane4)\n",
    "    \n",
    "x, y = [], []\n",
    "for i in range(len(dataSplit1)):\n",
    "    if i%2 == 0:\n",
    "        x.append(dataSplit1[i])\n",
    "    else:\n",
    "        y.append(dataSplit1[i])\n",
    "for i in range(len(dataSplit2)):\n",
    "    if i%2 == 0:\n",
    "        x.append(dataSplit2[i])\n",
    "    else:\n",
    "        y.append(dataSplit2[i])\n",
    "for i in range(len(dataSplit3)):\n",
    "    if i%2 == 0:\n",
    "        x.append(dataSplit3[i])\n",
    "    else:\n",
    "        y.append(dataSplit3[i])\n",
    "for i in range(len(dataSplit4)):\n",
    "    if i%2 == 0:\n",
    "        x.append(dataSplit4[i])\n",
    "    else:\n",
    "        y.append(dataSplit4[i])\n",
    "plt.scatter(x=x, y=y, c='r', s=40)\n",
    "plt.show()\n",
    "print(\"Shape of Vehicle Image\" +  str(vehicle_images_original[23].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return 60x60 heatmap of lanes\n",
    "def normLanes(lanes):\n",
    "    x, y = [], []\n",
    "    n = np.zeros((60,60))\n",
    "    for point in range(0, len(lanes)+1, normPoints):\n",
    "#         color = colors[c]\n",
    "        lane = lanes[0:point]\n",
    "        a,b = 0,0\n",
    "        for i in range(len(lane)):\n",
    "            if i%2 == 0:\n",
    "                x.append((lane[i]/1640)*240)\n",
    "                a = (lane[i]/1640)*60\n",
    "            else:\n",
    "                y.append((lane[i]/590)*240)\n",
    "                b = (lane[i]/590)*60\n",
    "            if a != 0 and b != 0 and not a >= 60 and not b >= 60:\n",
    "                n[int(b)][int(a)] = 1\n",
    "                a = 0\n",
    "                b = 0\n",
    "\n",
    "    \n",
    "    return x, y, n, n.ravel()\n",
    "def showImageWithLanes(image, lanes):\n",
    "    plot = plt.imshow(image)\n",
    "    plt.show()\n",
    "    colors = ['r', 'g', 'b', 'y']\n",
    "    color = 'r'\n",
    "    c = 0\n",
    "    \n",
    "    x, y, n, j = normLanes(lanes)\n",
    "    print(\"show:\",j)\n",
    "#     showPred(image, j)\n",
    "#     plt.scatter(x=x, y=y, c=color, s=20)\n",
    "    c = c + 1\n",
    "#     plt.show()\n",
    "#     plt.imshow(n, cmap='hot', interpolation='nearest')\n",
    "#     plt.show()\n",
    "def showPred(img, pred):\n",
    "    n = np.zeros((60,60))\n",
    "    row = pred.reshape(60,60)\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(60):\n",
    "        for j in range(60):\n",
    "            if row[i][j] > 0.5:\n",
    "                n[i][j] = 1\n",
    "                y.append(i*4)\n",
    "                x.append(j*(426/60))\n",
    "                a, b = (int((j*(426/60)))), int((i*4))\n",
    "                cv2.line(img,(a, b),(a, b),(50,50,50),7)\n",
    "    return img\n",
    "plt.imshow(cv2.cvtColor(cv2.resize(vehicle_images_original[700], (240, 240)), cv2.COLOR_RGB2GRAY))      \n",
    "plt.show()\n",
    "showImageWithLanes(cv2.cvtColor(cv2.resize(vehicle_images_original[700], (240, 240)), cv2.COLOR_RGB2GRAY), outputData[123])\n",
    "normalizedLanes = []\n",
    "for lanes in outputData:\n",
    "    _, _, _, l = normLanes(lanes)\n",
    "    normalizedLanes.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test data\n",
    "flattenImages = []\n",
    "for i in vehicle_images_original:\n",
    "    flattenImages.append(cv2.resize(i, (240, 426)))\n",
    "flattenImages = np.array(flattenImages, dtype=\"float\") / 255.0\n",
    "outputData = np.array(outputData)/426\n",
    "# print(flattenImages[0].size)\n",
    "data = flattenImages\n",
    "labels = np.array(normalizedLanes)\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, outputData, test_size=0.25, random_state=42)\n",
    "# print(trainX.shape, trainY.shape, testX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(426,240,3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(384, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model using SGD as our optimizer and categorical\n",
    "# cross-entropy loss (you'll want to use binary_crossentropy\n",
    "# for 2-class classification)\n",
    "print(\"[INFO] training network...\")\n",
    "sgd = SGD(lr=0.15, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "H = model.fit(trainX, trainY, validation_data=(testX, testY), epochs=3, batch_size=32)\n",
    "\n",
    "\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=16)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=['0', '0']))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model1.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model2.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "# score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "# print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"[INFO] serializing network and label binarizer...\")\n",
    "# model.save(\"model\")\n",
    "# # f = open(args[\"label_bin\"], \"wb\")\n",
    "# # f.write(pickle.dumps(lb))\n",
    "# # f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model prediction\n",
    "# image = cv2.resize(vehicle_images_original[13], (32, 32)).flatten()\n",
    "# image = np.array(image, dtype=\"float\") / 255.0\n",
    "# img = np.array(image)\n",
    "# print(np.array(data[2]).shape)\n",
    "# showImageWithLanes(vehicle_images_original[1], outputData[1])\n",
    "img = cv2.resize(vehicle_images_original[1200], (240,426))\n",
    "img = np.array(img, dtype=\"float\") / 255.0\n",
    "preds = loaded_model.predict(np.array([img]))\n",
    "# print(preds)\n",
    "img = cv2.resize(img, (426,240))\n",
    "# showImageWithLanes(img, preds[0])\n",
    "plt.imshow(showPred(img, preds[0]))\n",
    "plt.show()\n",
    "imgpath = glob.glob('./test3.jpg')\n",
    "print (imgpath)\n",
    "img1 = cv2.imread(imgpath[0])\n",
    "img = cv2.resize(img1, (240,426))\n",
    "img = np.array(img, dtype=\"float\") / 255.0\n",
    "preds = loaded_model.predict(np.array([img]))\n",
    "# print(preds)\n",
    "img = cv2.resize(img, (426,240))\n",
    "# showImageWithLanes(img, preds[0])\n",
    "plt.imshow(showPred(img, preds[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################### FIND CHESSBOARD CORNERS ###############################\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img = mpimg.imread('./camera_cal/calibration11.jpg')\n",
    "image_shape = img.shape\n",
    "print(image_shape)\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "ny = 6\n",
    "\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "objp = np.zeros((nx*ny,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2)\n",
    "\n",
    "fnames = glob.glob(\"camera_cal/calibration*.jpg\")\n",
    "\n",
    "for fname in fnames:\n",
    "    img = mpimg.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    if ret:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "# use the object and image points to caliberate the camera and compute the camera matrix and distortion coefficients\n",
    "ret, cameraMatrix, distortionCoeffs, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_shape[:2],None,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = mpimg.imread('./camera_cal/calibration02.jpg')\n",
    "undistorted = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "def process_image(img):\n",
    "    img = cv2.resize(img, (240,426))\n",
    "    img = cv2.undistort(img, cameraMatrix, distortionCoeffs, None, cameraMatrix)\n",
    "    j = img\n",
    "    img = np.array(img, dtype=\"float\") / 255.0\n",
    "    preds = loaded_model.predict(np.array([img]))\n",
    "    img = cv2.resize(j, (426,240))\n",
    "    img = showPred(img, preds[0])\n",
    "    return img\n",
    "imgpath = glob.glob('./test3.jpg')\n",
    "print (imgpath)\n",
    "img1 = cv2.imread(imgpath[0])\n",
    "img = cv2.resize(img1, (240,426))\n",
    "img = np.array(img, dtype=\"float\") / 255.0\n",
    "plt.imshow(process_image(img))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Vertices extracted manually for performing a perspective transform\n",
    "bottom_left = [0,426]\n",
    "bottom_right = [240, 426]\n",
    "top_left = [50, 240]\n",
    "top_right = [190, 240]\n",
    "\n",
    "source = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "\n",
    "pts = np.array([bottom_left,bottom_right,top_right,top_left], np.int32)\n",
    "pts = pts.reshape((-1,1,2))\n",
    "copy = img.copy()\n",
    "cv2.polylines(copy,[pts],True,(255,0,0), thickness=3)\n",
    "\n",
    "# Destination points are chosen such that straight lanes appear more or less parallel in the transformed image.\n",
    "bottom_left = [120,426]\n",
    "bottom_right = [240, 426]\n",
    "top_left = [120, 1]\n",
    "top_right = [240, 1]\n",
    "\n",
    "dst = np.float32([bottom_left,bottom_right,top_right,top_left])\n",
    "M = cv2.getPerspectiveTransform(source, dst)\n",
    "M_inv = cv2.getPerspectiveTransform(dst, source)\n",
    "img_size = (image_shape[1], image_shape[0])\n",
    "\n",
    "warped = cv2.warpPerspective(img, M, img_size , flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(copy)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(warped, cmap='gray')\n",
    "ax2.set_title('Warped Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "# white_output = './IMG_5254_output.mp4'\n",
    "# ## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "# ## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "# ## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "# ## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "# ##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "# clip1 = VideoFileClip(\"IMG_5254.mov\").subclip(20, 35)\n",
    "# clip1 = clip1.set_fps(10)\n",
    "# white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "# %time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
